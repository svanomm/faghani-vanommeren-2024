\documentclass[12pt]{article}
\usepackage{tocloft}% to configure the ToC <<<<<
\setlength{\cftsecnumwidth}{4.5ex}% set the width to the section number in the ToC <<<<<
\renewcommand{\thesection}{\Roman{section}.} 
\renewcommand{\thesubsection}{\quad \Alph{subsection}.}
\renewcommand{\thesubsubsection}{\qquad \roman{subsubsection}.}

\usepackage[style=authoryear,bibencoding=auto,strict,backend=biber,natbib,maxcitenames=2]{biblatex}

\usepackage{amssymb,amsmath,amsfonts,bbm,bm,eurosym,geometry,ulem,graphicx,color,setspace,sectsty,comment,float,caption,pdflscape,setspace,subfigure,array,hyperref}
\usepackage{xurl}
\usepackage[font=bf]{caption}
\usepackage{xcolor}
\usepackage[bottom]{footmisc}

\hypersetup{
    colorlinks,
    linkcolor={black},
    citecolor={blue!35!black},
    urlcolor={blue!35!black}
}
\addbibresource{bibliography.bib}

\normalem

\onehalfspacing

\geometry{left=1.0in,right=1.0in,top=1.0in,bottom=1.0in}

\begin{document}
\begin{titlepage}
\title{Staggered Difference-in-Differences Estimation for Antitrust Analysis: A Review of New Literature and Recommendations for Practitioners}
\author{Hassan Faghani\thanks{Director, Berkeley Research Group (BRG).} \and Steven VanOmmeren\thanks{
Managing Consultant, BRG. \\\\ We thank colleagues at BRG for providing helpful comments in forming this paper. The views expressed herein are solely those of the authors, who are responsible for the content, and do not necessarily represent the views of Berkeley Research Group. Any and all mistakes are our own. A replication package for our analysis is available at \url{https://github.com/svanomm/faghani-vanommeren-2024/}.
}
}

\date{\today}
\maketitle
\begin{abstract}
\noindent 
The aim of this paper is twofold: first, we discuss new literature surrounding difference-in-differences (DiD) methods with staggered treatment mechanisms. Second, we provide a resource for sound DiD analysis in expert testimony in light of these developments. We review relevant new papers and their most important conclusions. We then discuss the antitrust implications of three important topics: parallel trends, the not-yet-treated group, and data with customer entry and exit. We supplement this discussion with Monte Carlo analysis, in which we compare the performance of DiD estimators and quantify certain types of bias. Finally, we discuss the sensitivities and robustness checks that should underlay expert testimony going forward. DiD theory has come a long way in the academic literature since the 2010s, and we distill that knowledge into what we consider to be the new standard for robust DiD results in 2024.\\
\vspace{0in}\\
\noindent\textbf{Keywords:} difference-in-differences, staggered treatment, heterogeneity, antitrust
\vspace{0in}\\
\noindent\textbf{JEL Codes:} C18, C52, L40\\

\bigskip
\end{abstract}
\setcounter{page}{0}
\thispagestyle{empty}
\end{titlepage}
\pagebreak \newpage


\tableofcontents

\doublespacing

\newpage
\section{Introduction} \label{sec:introduction}
Understanding the effects of policy changes is among the fundamental problems of applied social sciences. In economic and legal studies, one of the most popular techniques for measuring the effects of policy changes is difference-in-differences (DiD) analysis.\footnote{We wrote a high-level summary of DiD and the new literature developments in early 2023. This paper provides more econometric detail and cites several papers that have been published since our previous article. \url{https://www.law360.com/articles/1568455/the-difference-in-differences-antitrust-analysis-is-evolving}.}  At its core, DiD is relatively simple to understand, contributing to its popularity. In DiD, a group of entities, such as firms, stores, or customers, that have been affected by an event of interest are compared against a similar group of entities that were not affected. We then analyze the trend over time of this difference---a difference (over time) in differences (between the affected and unaffected). DiD essentially combines two common impact methods (yardstick and before-after analysis) to yield a more robust estimate. The underlying assumption is that the studied policy is the only relevant change between the two groups once the treatment starts. The affected group is referred to as the “treatment group,” and the unaffected is the “control group.” A simple DiD visualization is shown in Figure \ref{fig:did-diagram}.
\begin{figure}[H]
    \centering
    \caption{Example of Simple DiD Analysis}
    \includegraphics[width=5in]{Figures/Diff in Diff Diagram.PNG}
    \label{fig:did-diagram}
    \vspace{5mm}
    \footnotesize \begin{singlespace*}
        \parbox{5.5in}{A hypothetical DiD example. Here, the treatment group experiences a policy change starting at the dashed vertical line. To calculate the average treatment effect, we compare the difference pre-/post-policy for the control group with that of the treatment group. The dashed blue line represents how the treatment group would have moved if it followed the control group’s behavior in the post-policy period.}
    \end{singlespace*}
\end{figure}
\noindent
DiD is commonly used in antitrust analyses. For example, it can measure harm from illegal conduct by modeling changes in revenue. This framework was used to estimate overcharges and damages from alleged anticompetitive behavior in the market for data management systems.\footnote{\textit{In re Dealer Management Systems Antitrust Litigation}, 581 F.Supp.3d 1029 (N.D.Ill., 2022). Part of the \textit{Daubert} challenge against Plaintiffs’ experts involved assessing a violation of the parallel trends assumption. \textit{Id} at 69.}  DiD was used to estimate overcharges to manufacturers from an alleged conspiracy to raise prices of coupon-processing fees.\footnote{\textit{Mr. Dee's Inc. v. Inmar, Inc.}, 2021 WL 4224720 (M.D.N.C., 2021), at *5. Plaintiff’s expert supplemented the DiD analysis with both a before-after (difference over time) and yardstick approach (contemporaneous difference between treatment and control). }  DiD measured whether Staples stores’ prices were lower when they faced local competition from Office Depot.\footnote{\citet{ashenfelter2004}, Equations 2 through 5 (discussing  \textit{Federal Trade Commission v. Staples, Inc.}, 970 F. Supp. 1066 (D.D.C., 1997)). While not described as such, these regressions are forms of two-way fixed effects (TWFE) models, which are a type of DiD analysis.}  And it was used to assess “whether and to what extent NorthShore's post-merger price increases were the result of increased market power resulting from the merger [with Highland Park Hospital].”\footnote{\textit{In re NorthShore Univ. HealthSystem Antitrust Litig.}, No. 07-cv-4446, 2018 WL 2383098, at *2, citing \textit{Messner}, 669 F.3d, at 818. Interestingly, the experts debated whether Plaintiff’s DiD analysis was valid in the presence of non-uniform (i.e. heterogeneous) price increases, a subject of the new literature.} 

DiD isolates the average effect of a policy change only under certain assumptions. The most prominent assumption is that the treatment group would have followed the same relative path as the control group absent the policy change. This assumption is called the \textbf{parallel} or \textbf{common trends assumption}. Equivalently, DiD attributes any change in the treatment group as being due to the policy change; it assumes that all other meaningful events are controlled for. Failing the parallel trends assumption can call into question the validity of DiD results and makes causal interpretation difficult.\footnote{This assumption is often a central topic of critique when DiD is used in antitrust analysis, and it is often included in \textit{Daubert} challenges.} In practice, it can be difficult to perfectly satisfy the parallel trends assumption. With non-experimental data, control groups will likely have some observable differences with the treatment group. However, econometricians have still extracted useful information from DiD models, adding caveats about uncertainty to their results rather than rejecting them entirely. We discuss how parallel trends tests and assumptions are affected by new DiD literature in more detail in \hyperref[sec:parallel-trends]{Section IV.A}.

Research questions are often more complicated than just measuring one average effect, and the nature of the data and policy of interest may further complicate things. To account for these complications, DiD analysis of antitrust conduct is typically implemented with a linear regression, which can control for observable factors and estimate the statistical significance of results. For example, DiD analysis of prices in an alleged conspiracy may include additional relevant controls for supply and demand.

One common complication in a DiD framework is differential treatment timing, where different units affected by the policy or conduct start or end their treatment at different times. A special case of differential treatment timing, where the treatment units remain permanently affected after their treatment, is called staggered treatment.\footnote{We examine binary staggered treatment in this paper, which additionally assumes that the treatment effect is immediate and can only be turned on or off. A non-binary treatment example would be drug trials which give different amounts of the drug to different treatment units. Binary treatment is most common in antitrust work, where we usually have no way of knowing or characterizing “how much” of the treatment is happening. However, certain types of non-binary treatment can be effectively estimated by the methods we discuss here. For example, the ramp-up effects of a conspiracy could be captured by measuring treatment effects over time.}  Staggered treatment designs are common in policy evaluation and antitrust analysis. For example, merger analysis may examine price effects surrounding acquisitions in different local markets over time, and price-fixing mechanisms may involve rolling out price increases for certain products over time. An example of a staggered treatment design is shown below in Figure \ref{fig:visual}. Note how in certain years, there are units that have not yet been affected by the policy change (the “not-yet-treated” group), and others who have. DiD analysis in this setting will use the not-yet-treated group, along with the prototypical control group (now called the “never-treated” group), in forming the estimated policy effect. How exactly this works is a focal point of new literature that we discuss below.
\begin{figure}[H]
    \centering
    \caption{Example of Staggered Treatment Mechanism}
    \includegraphics[width=5in]{Figures/Visual Staggered Treatment.PNG}
    \label{fig:visual}
    \vspace{2mm}
    \footnotesize \begin{singlespace*}
        \parbox{5.5in}{In this diagram, each row represents an individual in the data. The first two rows never experience the policy change. The remaining four rows each experience the effects of the policy starting at different times, from 2017 to 2020. In this case, the policy and its treatment effect are staggered across the units.}
    \end{singlespace*}
\end{figure}
\noindent There are also cases where entities in the treatment and control groups can “enter” or “exit” the data for some part of the analysis. In transaction data, it is likely to observe some customers for only part of the timeframe of the data; new customers come in and others leave. This can complicate an antitrust analysis: are customers leaving the data randomly, or is it because a conspiracy raised the price of their favorite products too much?

One can imagine several other complications of applied DiD analysis. An important question is: how do these complications interact with the policy effect we’re trying to measure? It is likely (and sometimes expected by economic theory) that overcharges change over time as the market responds to supracompetitive prices or cartel members attempt to cheat a conspiracy. Certain groups of customers may be easier to overcharge than others, depending on buyer power, asymmetric information, or competitive conditions. It is also possible that when customers renew long-term contracts well into a conspiracy, their overcharges could differ from customers who renewed during the beginning stages of the conspiracy. All of these examples require special consideration when performing DiD analysis.

In recent years, a large body of literature on DiD analysis has appeared which aims to better understand how such complications affect our regression results. Academics have largely confirmed the suspicions of careful applied econometricians by proving that results are biased if we do not account for the studied policy and its effects appropriately. But of particular interest, the new research has revealed a bias in DiD estimates inherent to the staggered nature of the treatment mechanism. The new literature has provided several new estimators that are robust to certain types of misspecifications, detailed sets of assumptions that underlie their results, and many other sensitivities and checks to diagnose issues common to DiD analysis.\footnote{The new DiD literature has caught on quickly in the academic space, with some seminal papers already have several thousand citations. It is already a lecture topic in current PhD-level econometrics courses and has been the subject of several conferences, seminars, and special journal issues. The new literature is also entering antitrust expert analysis. The authors have personally encountered some of the new papers in antitrust expert testimony, including \citet{CS2021} and \citet{goodman-bacon2021a}.}

We review the main developments in DiD literature in \hyperref[sec:literature]{Section II}. \hyperref[sec:analysis]{Section III} summarizes the new estimators we think are best suited for antitrust work. \hyperref[sec:antitrust]{Section IV} discusses three topics of particular interest for antitrust practitioners. Results using a Monte Carlo analysis are reported in \hyperref[sec:analysis]{Section V}. In \hyperref[sec:conclusion]{Section VI} we conclude.

\section{Forbidden Comparisons and Weighting Issues in Staggered DiD} \label{sec:literature}
It is typical for DiD analyses (in antitrust or otherwise) to use a linear regression with fixed effects to control for confounding factors that might explain changes in an outcome variable such as price. In particular, many models include fixed effects for both the time and unit dimensions in the data. These regressions are called two-way fixed effects or TWFE models and take the following form:
\begin{equation}
    y_{it} = \alpha_i + \lambda_t + \boldsymbol{\gamma}  D_{it} + \beta X_{it} + \epsilon_{it},
\end{equation}
where $y_{it}$ is the outcome of interest, such as price, $\alpha_i$ are unit fixed effects, $\lambda_t$ are time period fixed effects, $D_{it}$ is an indicator variable which is 1 for being actively affected by the policy and 0 otherwise, $X_{it}$ represents other observable variables, and  $\epsilon_{it}$ captures variations in the data that cannot be explained by the model.\footnote{This model specification is referenced in many popular econometric textbooks, including  \citet{angrist2009mostly}, Section 5.2.1; \citet{hansen2022econometrics}, p. 671; and \citet{cameron2020}, pp. 768-770. \\\\ TWFE is considered a “default” DiD specification when there are multiple groups and time periods. This is often a matter of convenience. Rather than identifying which confounding events or characteristics need to be controlled for in the model, TWFE controls for all time-invariant and unit-invariant heterogeneity. But these fixed effects do not control for time-varying events that affect a subset of the units or which vary by unit.} Unlike a classical DiD regression, TWFE regressions will run and estimate effects when treatment is staggered (i.e. with multiple treatment times).

TWFE models are very common, as detailed by \citet{de2020two}, who found that nearly one in five empirical articles from 2010 to 2012 published in the American Economic Review used the specification to estimate treatment effects.\footnote{\citet{de2020two}, p. 2964.} A series of econometric papers starting around 2017 closely examined the composition of TWFE models when there are multiple time periods, treatment units, and under staggered treatment, i.e. under more realistic scenarios where researchers commonly use a DiD framework. What the papers found is that seemingly innocuous violations of the underlying DiD assumptions lead TWFE and other models to estimate something unexpected. Rather than measuring the average treatment effect on the treated (ATT) as researchers typically expect, TWFE instead measures a different average of treatment effects. This average can be so different that it may measure an effect in the opposite direction of the ATT.

\citet{goodman-bacon2021a} provides a simple framework for understanding what TWFE actually measures in a staggered setting. Prof. Goodman-Bacon proves that the treatment effect measured in a staggered setting is actually a weighted average of many smaller, component DiD coefficients within the data. In fact, it is equal to a weighted average of \textit{all possible} two-by-two DiD designs in the data, where one group whose treatment status changes at a given time is compared to another group whose treatment status does not change.\footnote{\citet{goodman-bacon2021a}, pp. 257-260 (Theorem 1).
\\\\
There are other decomposition results from the literature. For example, \citet{de2020two} and \citet{borusyak2024revisiting} show that TWFE also measures a weighted average of all possible group-time ATTs. This is different from Prof. Goodman-Bacon's decomposition into component DiDs. Using our example, there would be only three group-time ATTs: the effects for Cohort 1 at time 1, Cohort 1 at time 2, and Cohort 2 at time 2. While Goodman-Bacon decomposition weights are positive, the weights of the ATTs can be negative. This is what the literature is referring to when discussing negative weights. 
}

We illustrate Prof. Goodman-Bacon's decomposition result with an example. Suppose that we measure overcharges from a price-fixing conspiracy, in which one cohort of colluding stores raise their prices at time 1, and another cohort raise their prices at time 2. We also have data from a control group of stores that are known to not be part of the conspiracy. A typical strategy would be to run a TWFE model to estimate a single average price overcharge for all colluding stores. In this case, our overcharge estimate would be a weighted average of four different DiD comparisons:
\begin{enumerate}
    \item Cohort 1 vs control group, before/after time 1
    \item Cohort 1 vs Cohort 2, before/after time 1
    \item Cohort 2 vs control group, before/after time 2
    \item Cohort 2 vs Cohort 1, before/after time 2.
\end{enumerate}

In each comparison, the treatment group changes from pre-conspiracy prices to conspiratorial prices, while the ``control group" does not change its status. Comparisons 1 and 3 are just like a typical (non-staggered) DiD analysis, using the never-treated units as a benchmark. Comparison 2 demonstrates how cohorts who are not yet affected by the conspiracy can be used as an effective control, which we discuss more below in \hyperref[sec:notyettreated]{Section IV.B}. But Comparison 4 presents a problem: at time 2, Cohort 1 is already charging conspiratorial prices. Using conspiratorial prices as our benchmark violates the basic idea of DiD, yet TWFE models include these so-called “\textbf{forbidden comparisons}.”\footnote{\citet{de2023two}, Section 2.2 (The origin of the problem: ‘forbidden comparisons’).} A visual example of decomposition is shown below, with the forbidden comparison highlighted in gray.

\begin{figure}[H]
    \centering
    \caption{Example of TWFE Decomposition}
    \includegraphics[width=5in]{Figures/DiD Decomposition Diagram.PNG}
    \label{fig:decomp}
    \vspace{3mm}
    \footnotesize \begin{singlespace*}
        \parbox{5.5in}{This diagram charts the average prices for three groups of stores. Cohort 1 raises their prices first, with Cohort 2 raising their prices at a later time. The Control Group stores do not raise their prices during the period of interest. A TWFE model of this data would decompose into four component DiD comparisons, with Comparison 4 being a forbidden comparison in which Cohort 1 is used as a ``control group" when it is actively treated (i.e. actively colluding on prices).}
    \end{singlespace*}
\end{figure}

While the fact that forbidden comparisons occur in TWFE models is worrying on its own, it is not obvious if or how they would affect the regression results. After discovering the issue, the new literature has studied under what circumstances forbidden comparisons lead to severe bias or misinterpretation of results. The key takeaway is this: if treatment effects vary by when the treatment started, or if they vary over time, then forbidden comparisons can substantially distort TWFE models from the estimates researchers often seek to measure.\footnote{Another common DiD model will augment the TWFE with interaction terms to measure separate treatment effects over time. The new literature (including \citet{sunabr2021a} and \citet{borusyak2024revisiting}) shows that the same results regarding forbidden comparisons apply to these models.} In certain scenarios where the already-treated benchmark group increases more than the studied treatment cohort, \citet{baker2022much} show that TWFE estimates can be \textit{negative} when all treatment effects are \textit{positive.}\footnote{\citet{baker2022much}, Figure 2, Simulation 6. For example, suppose that in our Figure \ref{fig:decomp}, instead of a flat line at time 2, Cohort 1 increases its prices by an additional \$10, where Cohort 2 only increases by \$5. Then Comparison 4 would find a ``treatment effect" of -\$5, since the treatment group increases less than the ``control group." This forbidden comparison would then decrease the resulting TWFE average.} 

Additional insights come from examining the weights that form the weighted average TWFE coefficient. \citet{goodman-bacon2021a} shows that the weights depend on how many units are in each cohort and in the control group, how early/late the store becomes treated in the data, and the relative sizes between each treatment cohort. As a result, simply increasing the number of time periods in a dataset will change the weights and resulting TWFE estimates.\footnote{\citet{goodman-bacon2021a}, p. 259 (``Theorem 1 implies that changing the number or spacing of time periods changes the weights (in addition to potentially changing the 2x2 DDs). \ldots Therefore, panel length alone can change TWFEDD estimates substantially even if the 2x2 DDs themselves are constant.").} \citet{de2020two} explain that TWFE effectively gives more weight to short-term treatment effects, which we demonstrate with our Monte Carlo analysis below.\footnote{\citet{de2020two}, p. 2972 (``$\beta_{fe}$ is more likely to assign a negative weight to periods where a large fraction of groups are treated, and to groups treated for many periods.").}

Along with diagnosing the forbidden comparisons problem with staggered treatment and heterogeneity-masking effects of TWFE models, the new literature has proposed a swathe of alternative models and sensitivity tests which address the issues. The general solution is straightforward: \textbf{eliminate the forbidden comparisons from your DiD estimation}. There are a variety of ways to do this, which we discuss in the next section.

\section{Robust Analysis with Staggered Treatment} \label{sec:equations}
We now discuss the form and implementation of some of the existing and new methods and sensitivities from the literature. Our discussion is limited to new estimators we believe are better suited to antitrust analysis. The methods we discuss are derived from ordinary least squares (OLS) regression techniques, which makes them relatively easier to explain to a general audience, and they are also more practical with large, transaction-level data. 
\subsection{Existing DiD Estimators}
The most basic DiD regression uses only 3 indicator variables: “treated,” which is 1 for affected units and 0 for control group units, “post” which is 1 after the start of the policy and 0 otherwise, and “post-treated,” which is the interaction of the two. The coefficient on “post-treated” is the measured DiD effect.
\begin{equation}
    y_{it} = \gamma \cdot \text{PostTreated}_{it} + \alpha\cdot \text{Treated}_i + \beta \cdot \text{Post}_t + \epsilon_{it}
\end{equation}
The basic TWFE model replaces “treated” with a set of unit fixed effects, and “post” with a set of time fixed effects:\footnote{Many other variations of TWFE and basic DiD models exist. For example, one might replace time fixed effects with covariates that appropriately control for variation over time. Polynomial terms might be included to account for non-linear relationships. Other models may add time-trend interactions to capture changing covariate relationships over time.}
\begin{equation}
    y_{it} = \gamma D_{it} + \alpha_i + \lambda_t + \beta X_{it} + \epsilon_{it},    
\end{equation}
where one controls for agents ($\alpha_i$), time ($\lambda_t$), and optional control variables ($X_{it}$). The coefficient of interest is $\gamma$ which quantifies the effect of the policy. “$D_{it}$” in the equation is the same as “PostTreated$_{it}$” in the previous equation. Researchers typically report standard errors clustered at the unit level to account for potential serial correlation.\footnote{For further reading, see \citet{bertrand2004}.} 

The dynamic TWFE model then interacts the post-treated variable with relative-time indicators (i.e. time before/after starting treatment). Note that there are several treatment effects being measured now, one for each relative time period. This allows researchers to see if treatment effects change over time.
\begin{equation}
    y_{it} = \sum_{r=p}^R\left(\gamma_r\cdot\mathbbm{1}[t_r=r]\right) + \alpha_i + \lambda_t + \beta X_{it} + \epsilon_{it},    
\end{equation}
In this equation, “$t_r$” is relative time, i.e. the number of time periods before/after the start of treatment.\footnote{An example would be an indicator for relative time = -2, which equals 1 for observations 2 time periods before starting treatment.} Some researchers include pre-exposure periods in the model.  Parallel trends and anticipation effects are commonly assessed by testing whether pre-exposure coefficients are different from zero. In a staggered treatment design, relative times would average across several calendar periods. For example, “1 year after starting treatment” would be 2008 for units who start in 2007, and 2010 for those who start in 2009.
\subsection{New DiD Estimators}
All of the estimators we discuss below automatically remove the forbidden comparisons that would taint a typical TWFE model when treatment is staggered. As a result, antitrust practitioners using a TWFE framework should examine at least one of the models below to ensure that forbidden comparisons do not significantly skew their results away from the average treatment effect.

\citet{sunabr2021a}’s estimator modifies the dynamic model to also estimate separate treatment effects by treatment cohort. A “cohort” is a group of units that start their treatment at the same time.\footnote{For example, states that changed their minimum wage in 2010 would be in a different cohort than states that changed in 2012.}  By saturating the model with separate treatment effects, their estimator removes the forbidden comparisons that could lead to bias in a standard DiD model.\footnote{As it is saturated, certain indicators are omitted to prevent collinearity. Researchers typically omit the indicators for one period before starting treatment. Also, when there are no never-treated units in the data, another set of indicators must be removed, typically the last set of time indicators. Note that the authors did not examine how adding covariates to the model would affect results.}   Like the typical dynamic TWFE model, the policy effect is estimated with respect to how long units have been subjected to the treatment. Unlike the dynamic TWFE model, however, the \citet{sunabr2021a} model additionally measures how units that start their treatment earlier in time differ from those who start their treatment later.
\begin{equation}
    y_{it} = \sum_{v=c}^C\sum_{p=r}^R\left(\gamma_{vp}\cdot\mathbbm{1}[t_r=p]\cdot \mathbbm{1}[\text{cohort}_i=v]\right) + \alpha_i + \lambda_t + \epsilon_{it},
\end{equation}
The \citet{wooldridge2021two} estimator is essentially an extension of the Sun and Abraham method.\footnote{Prof. Wooldridge offers two equivalent ways of estimating cohort-specific treatment effects: regular TWFE-style models, and Mundlak-style estimators which include group averages. For simplicity, we show the TWFE-style approach.}  The Wooldridge model not only measures treatment effects by cohort and over time, but it also allows for the treatment effect to vary with respect to covariates.\footnote{Prof. Wooldridge and other papers tend to focus on time-invariant control variables; these are seen as “safer” to include in DiD analysis because it’s less likely that the controls would affect treatment status and vice versa. Special care must be given to time-varying covariates to ensure their exogeneity to the treatment effect. For new research on interpreting DiD effects with time-varying controls, see \citet{caetano2023} and \citet{wooldridge2023nonlinear}, C60 (Section 7.3).} Besides allowing more flexibility in the model, this framework has a more realistic parallel trends assumption: control and treatment units would move similarly over time \textit{after controlling for observed covariates} in the absence of the treatment effect. With $L$ covariates, and using $\dot{x}$ to represent cohort-demeaned controls, the model is:\footnote{This is Prof. Wooldridge’s equation 6.33 on p. 44. As explained in the paper, demeaning $x$ by cohort is not necessary for correct treatment effect estimation, but it allows for easier interpretation of the covariate-interacted treatment effects ($\theta_{vq}\cdot\dot{x}_{itk}$) in terms of the ATT.}
\begin{multline}
    y_{it} = \sum_{v=c}^C\sum_{q=t}^T\left(\gamma_{vq}\cdot\mathbbm{1}[t=q]\cdot \mathbbm{1}[\text{cohort}_i=v]\right) + \alpha_i + \lambda_t \\
    + \sum_{x=k}^L\sum_{v=c}^C\sum_{q=t}^T\left(\theta_{vq}\cdot \mathbbm{1}[t=q]\cdot \mathbbm{1}[\text{cohort}_i=v] \cdot \dot{x}_{itk}\right) + \alpha_i X_{it} + \lambda_t X_{it} + \beta X_{it} +\epsilon_{it},
\end{multline}
Note that the first part of the equation mirrors the Sun and Abraham estimator, while the rest of the equation incorporates flexible treatment interaction with the covariates.\footnote{The Sun and Abraham model is in terms of relative time, while the Wooldridge model uses calendar time. This leads to slightly different notation and interpretation of coefficients, but the estimated effects are the same.}  The additional terms include a set of cohort-time interactions for each covariate, a full set of unit indicators for each covariate, a full set of time indicators for each covariate, and the covariates themselves. Prof. Wooldridge explains how to aggregate these treatment effect estimates and adjust their standard errors for sampling variation in the covariates, which may provide more conservative inference than other new estimators.\footnote{\citet{wooldridge2021two}, pp. 32-33.} Prof. Wooldridge uses the term Extended TWFE or ETWFE to refer to models that measure additional effects compared to the original TWFE framework, such as the \citet{sunabr2021a} and \citet{wooldridge2021two} methods.

The \citet{borusyak2024revisiting} and \citet{gardner2022a} estimators both use an imputation approach, in which the appropriate unit and time effects are estimated from a regression on untreated observations, and then a second step determines the policy effect. The Borusyak et al. procedure works by regressing on fixed effects for untreated observations only (denoted by the “0” superscript), then projecting these effects onto the treated observations and forming an observation-specific treatment effect estimate. The results from the first step (denoted $\Hat{y}_{it}^0$ ) represent the model’s prediction of treatment unit outcomes in absence of the treatment effect.
\begin{align}
    1. \quad & y_{it}^0 = \alpha_i + \lambda_t + \epsilon_{it} \\
    2. \quad & \gamma_{it} = y_{it} - \Hat{y}_{it}^0
\end{align}
Researchers can then aggregate the treatment effect estimates as needed.

The Gardner method is similar but automatically aggregates the estimated effect. After running the first step (regression on untreated observations), a second step regresses adjusted outcomes on treatment status:
\begin{equation}
(y_{it} - \Hat{y}_{it}^0) = \gamma D_{it} + \epsilon_{it}    
\end{equation}
Both papers discuss how covariates may be incorporated into the model and how treatment effects can be estimated over time, by cohort, or just a single average effect.

Calculating standard errors for imputation treatment effects is different from the ETWFE methods, since researchers must account for variation coming from both estimation steps. Borusyak et al. recommend a conservative inference method which carries over regression residuals from the first step.\footnote{\citet{borusyak2024revisiting}, pp. 19-21 (Theorem 3).}  Prof. Gardner instead shows how his two regressions can be estimated simultaneously using GMM.\footnote{\citet{gardner2022a}, pp. 12-13.}
\subsection{Discussion}
While its flexibility can be beneficial, the full Wooldridge regression will include an extremely large number of variables if there are many treatment cohorts and covariates.\footnote{The number of variables in the regression grows approximately on the order of (number of cohorts squared) times (number of covariates). After partialling out the fixed effects, a TWFE implementation includes $1 + n(Q-q+T+1) + (n+1) \sum_{i=q}^Q(T+1-i)$ variables, where $n$ is the number of covariates, $T$ is the number of time periods, $q$ is the time of the first cohort, and $Q$ is the time of the last cohort. This assumes that units become treated in each time between $q$ and $Q$ and each cohort stays treated through the end of the data. For example, with 2 covariates, 20 time periods, and treatment cohorts between times 10 and 15, the regression would have 206 variables vs just 4 in a standard TWFE model.}  Besides running very slowly or not at all with large data, Wooldridge-type models may lack precision by estimating so many effects.\footnote{See \citet{faletto2023a} for a regularization approach to gain estimator efficiency in the presence of sparsity among the Wooldridge controls. But this technique does not reduce the (potentially infeasibly large) time needed to run such regressions. Future research might look into pre-regression dimensionality reduction as a method to combine and reduce the number of variables feeding into ETWFE-type models.}  With a priori knowledge, practitioners can reduce the variable count by restricting treatment patterns.\footnote{For example, if you believe that the treatment effect is constant over time, you can remove the time-specific treatment effects from the equation and only allow for cohort-specific effects.}  Binning variables is another common method for reducing variable count, in which (for example) treatment effects in monthly data would be measured by quarterly or yearly treatment effects. However, this is not without potential issue, as discussed in \citet{borusyak2024revisiting} Section 5.2.1 and Figure 3. They find that DiD analysis from \citet{broda2014} changes dramatically when removing the binning technique, and Borusyak et al. conclude that  estimating monthly effects on the weekly data imposes a “short-term bias,” where positive weights are given to earlier weeks in the month, and negative weights are given to the last week in each month. Borusyak et al. and Sun and Abraham provide strategies to estimate these weights using the Frisch-Waugh-Lovell theorem (essentially an auxiliary regression of treatment status on fixed effects).\footnote{\citet{borusyak2024revisiting}, Appendix A15 (Proof of Proposition 2). \citet{sunabr2021a}, p. 181 (Equation 13)}  Researchers who are binning should run these regressions as sensitivities to assess potential short-term bias in their models.

In the ETWFE models, practitioners often want to report a single coefficient, or one coefficient per calendar period. Sun and Abraham explain that it is easy to aggregate the coefficients after estimation; one can simply use sample probabilities for each cohort-period, or alternatively weight the probabilities by revenue or volume for damages analysis if the evidence suggests doing so.\footnote{\citet{sunabr2021a}, p. 186 (Section 4.1, Step 3). See also \citet{borusyak2024revisiting}, p. 16 (Theorem 2, Step 3).}  In any case, these methods circumvent the main problem with the original DiD models: they all eliminate the forbidden comparisons and provide control over the weighted average of treatment effects being calculated.
\\
\textbf{Sensitivities}: While we have described some possible sensitivities for expert analysis work here, we provide a more comprehensive list in  \hyperref[sec:appendixa]{Appendix A} below.
\section{Special Considerations for Antitrust Practitioners} \label{sec:antitrust}
We now discuss three topics that we consider particularly important for antitrust analysis: parallel trends assumptions, the not-yet-treated group, and unbalanced panels. Then in  \hyperref[sec:analysis]{Section V}, we investigate some related properties of staggered DiD in a Monte Carlo analysis.
\subsection{Cautions on Parallel Trends} \label{sec:parallel-trends}
Antitrust practitioners often use postestimation tests or visual inspection of the data to assess the parallel trends assumption underlying DiD results. But the new literature explains that conventional parallel trends test results should be taken with caution and skepticism.\footnote{The new literature has also proposed new parallel trends tests that are robust to the issues discussed above. See \hyperref[sec:appendixa]{Appendix A} for details.} \citet{roth2023s} summarize many issues with testing for parallel trends brought up in recent years. First, tests can suffer from low statistical power in smaller datasets.\footnote{\citet{roth2023s}, p. 2233.}  Second, selecting models based on what “passes” the parallel trends test induces testing bias.\footnote{See \citet{roth2022a} for an in-depth discussion of such biases and practical considerations.}  Third, in large datasets, it is likely that the parallel trends testing coefficients will be statistically significant.\footnote{This is true for most DiD models in antitrust analysis with transactional data, in our experience.} Rather than accepting or rejecting a DiD model on the statistical significance of parallel trends tests alone, practitioners should seek a more comprehensive understanding of how a violation of parallel trends would affect the results in context. 

From the new literature, \citet{rambachan2023more} (discussed in \citet{roth2023s}) pose a framing question: How large must the bias from unparallel trends be to make the resulting treatment effect statistically insignificant?\footnote{\citet{rambachan2023more} at Section 6.2. \citet{roth2023s} at section 4.5 (“one type of restriction [Rambachan and Roth] consider states that the magnitude of the post-treatment violation of parallel trends can be no larger than a constant M times the maximal pre-treatment violation. … This indicates that to invalidate the conclusion of a positive effect, we would need to allow for a post-treatment violation of parallel trends [M] times larger than the maximal pretreatment violation.”).}  Several sensitivities follow from this question, ranging from visual inspection to alternative model specifications.\footnote{See \hyperref[sec:appendixa]{our Sensitivities Appendix below} for more detail.}  This framework is of particular interest for antitrust impact analysis, where bias from lack of parallel trends can make or break an expert’s conclusion or lead to \textit{Daubert} exclusion. Experts should know how much the parallel trends assumption can be violated while still estimating a significant treatment effect. Importantly, the literature seems to point to the conclusion that a statistically significant (but economically insignificant) difference in parallel trends, particularly in large datasets, is not a fully reliable measure to invalidate DiD results.\footnote{\citet{roth2023s}, p. 2234 (``Indeed, it seems likely that with enough precision, we will nearly always reject that the parallel trends assumption holds exactly in the pre-treatment period. Nevertheless, we may still wish to learn something about the treatment effect, especially if the violation of parallel trends is `small’ in
magnitude.").}

An additional caution on parallel trends comes when covariates are added to the regression. While adding covariates can make the parallel trends assumption more realistic (trends in outcomes are parallel \textit{after conditioning on covariates}), DiD models implicitly assume that all covariates are exogenous to the policy effect, and/or that covariates enter linearly into the conditional mean function. Failing those assumptions will bias your results in an unknown direction, and the new estimators are not robust to these types of misspecification. The flexible Wooldridge model discussed above allows policy effects to vary by covariates, but still assumes that the treatment effect does not influence the covariates. Practitioners should weigh the benefits of including covariates with the risk of bias from endogeneity in their models.

In any case, we think that the new literature has weakened the assurance of postestimation parallel trends tests. In expert testimony, work in support of a DiD analysis should put more effort into providing sensitivities such as in Rambachan and Roth’s “what-if” analysis, as well as give theoretical justification of approximately conditional parallel trends. Work against DiD analysis should not rest on a statistically significant postestimation parallel trends test as a complete invalidation of a model; instead, practitioners should demonstrate that the resulting bias is economically meaningful. This could mean showing that damages disappear under a model which corrects for uncommon trends, or that the but-for predictions of the model are substantially different from reality.
\subsection{Not-Yet-Treated Group as a Source of Identification} \label{sec:notyettreated}
A consequence of staggered treatment designs is that at certain times, some units are currently experiencing the treatment, while others will be treated, but haven’t yet started their treatment (the “not-yet-treated group”). Others still may never experience the treatment (the “never-treated group”). The not-yet-treated group does not exist in a common-timing treatment design. However, the not-yet-treated group offers both benefits and potential drawbacks to applied researchers.

Classical DiD models require a control group of units that never experience the treatment. In staggered models, however, the not-yet-treated group can be used as an effective control group under certain conditions. In fact, the not-yet-treated group can sometimes be a better control than the conventional control group. A common criticism of antitrust DiD analysis is that units who never experience the policy change are too different from the treatment group. In this case, researchers can remove never-treated units entirely, taking advantage of the staggered treatment assignment to use not-yet-treated units only.

The not-yet-treated DiD model is also different from a standard before-after regression. Before-after models (with one treatment time) have no unaffected units after the start of treatment. But in a staggered setting, the data allow a contemporaneous effective control group for all cohorts except the very last one.\footnote{This is because if all cohorts eventually become treated, then there cannot be untreated units by the last time period. Some papers suggest removing the last period of data from the model to treat the last cohort as a “never-treated” group. \citet{wooldridge2021two}, p. 52.}  For example, by the time cohort 1 becomes treated, cohort 2 has not yet been treated, so at time 1, it is a control group for cohort 1. Similarly, cohort 3 is a control for cohort 2 at time 2, and so on.

Finally, the presence of two groups of effective controls (never-treated and not-yet-treated) means that parallel trends could hold for one (or both) of these groups. Some papers have defined separate parallel trends assumptions for each group (\citet{CS2021}), while others treat them the same (\citet{borusyak2024revisiting}, \citet{gardner2022a}).\footnote{\citet{CS2021}, p. 204 (Assumptions 4 and 5). \citet{borusyak2024revisiting}, p. 8 (Assumption 1). \citet{gardner2022a}, Equation 1.}  Researchers should consider which of these groups is more likely to satisfy parallel trends based on context. But in practice, the assumption is often based on data availability.\footnote{\citet{CS2021}, p. 205.}  We recommend running three types of models if data is available: one using the never-treated group, one with the not-yet-treated group, and one using both groups. Substantially different results from these models may indicate a compositional difference between the two control groups and may be worth exploring.

\subsection{Unbalanced Panels and the Always-Treated Group}
It is often the case that units (e.g. customers, suppliers, stores) are not present for the entire period of the data. In practice, units may enter into the analysis or exit in two ways. First, units can be partially present in the data because of a sampling issue. Second, units can be present in the data because they truly enter or exit during the period of the analysis (i.e. with no sampling issue). While the first type of partial presence is an important issue in itself, we focus on the second situation. Entry and exit within a staggered treatment design brings additional sources of concern for DiD analysis.

In panel data, if units are missing for some periods, then it is called an unbalanced panel (as opposed to a balanced panel). General theories related to dealing with unbalanced panel data are beyond the scope of this paper.\footnote{See generally, \citet{wooldridge2010a}, Chapter 17 (“Sample Selection, Attrition, and Stratified Sampling”) and \citet{cameron2020}, Chapter 27 (“Missing Data and Imputation”).}  However, we highlight a special case where a unit is not present either before or after the policy implementation in a DiD analysis. For example, a store may open in the midst of a price-fixing conspiracy affecting other local stores. In this example, the store has no “before” period to compare to in a typical DiD scenario; it is part of the ``always-treated" group.
\begin{figure}[H]
    \centering
    \caption{Example of Unbalanced Panel with Staggered Treatment}
    \includegraphics[width=5in]{Figures/Visual Staggered Unbalanced Treatment.PNG}
    \vspace{2mm}
    \footnotesize \begin{singlespace*}
        \parbox{5.5in}{Example of a staggered treatment mechanism with unbalanced data. Unit 4 has no “before” period and so is part of the always-treated group.}
    \end{singlespace*}
    \label{fig:visual-unbalanced}
\end{figure}
\noindent In a staggered TWFE or similar DiD model, the always-treated group will be automatically included in the analysis (it is not removed from the regression). But the model implicitly assumes that the policy effect on those units is similar to the average effect of the policy on units that are present (even partially) before and after the start of the policy. In contrast, if the treatment effect is different for always-treated units (for example because they tend to appear later in the data and the treatment effect is dynamic), then omitting them would change the estimated effect in a TWFE model. We recommend running the regression both with and without them to quantify their importance to the treatment effect.

When utilizing the always-treated group, antitrust practitioners must justify the assumption of similarity with the other treated units. In some scenarios, it may make sense that treatment effects are different for the always-treated units. For example, a cartel may find more leverage in overpricing new customers than customers that existed before the conspiracy (who are familiar with competitive prices). On the other hand, it’s also possible that a cartel could lure in new customers with competitive prices, then increase the prices later. The DiD estimators we discuss would correctly capture this effect only if the cartel ramps up the new customers’ prices in the same way as for others in the same treatment cohort. Depending on case-specific context, it may be worthwhile to compare trends for always-treated units to other treated units within the same cohort, if data is available.

\citet{de2023two} identify risks associated with the always-treated group in terms of weights given to the single DiD coefficient: cohorts that are always treated are more likely to receive negative weight in the TWFE averaging.\footnote{\citet{de2023two}, p. 5 (“Accordingly, all the weights are likely to be positive when there is no group that is treated most of the time, and no time periods where most groups are treated.”).}  This is mitigated by the new estimators we have described above.

Some types of new estimators from the literature explicitly remove always-treated units. Imputation-based estimators from \citet{borusyak2024revisiting} and \citet{gardner2022a} calculate the fixed effects from a regression on untreated observations, then estimate the treatment effect by partialling out the fixed effects. With unit-level fixed effects, there is no pre-treatment data for the always-treated unit by definitions. Prof. Gardner hypothesizes that an alternative method could be used to retain always-treated units, so long as the conditional mean function is specified correctly, but this requires justification.\footnote{\citet{gardner2022a}, note 8.}

\citet{borusyak2024revisiting} note that in unbalanced panels, if the composition of units within each cohort changes over time, then cohort-based estimators can be biased.\footnote{Cohort-based estimators are methods that include fixed effects at the treatment cohort (rather than unit) level. In balanced panels, cohort- and unit-based estimators are equivalent when standard errors are clustered at the unit level.}  This is because cohort-based estimators assume a constant composition within the cohort over time.\footnote{\citet{borusyak2024revisiting}, Appendix A2-A3 (“Our unit fixed-effects model can handle missing observations even when the composition of units changes over time, while cohort-based parallel trend assumptions (e.g. that $E[Y_{i,t+1}(0) - Y_{it}(0) | E_i]$ does not vary with $E_i$) may be unattractive; similarly, estimation with cohort, rather than individual, fixed effects can lead to biases with incomplete panels.”).}  The benefit of cohort-based estimators is that they can retain some of the data that would otherwise be dropped with unit-level estimators discussed above.

In the Monte Carlo results presented below, we report \hyperref[fig:estimators-balanced]{simulation results} which indicate that with highly unbalanced data, even the new DiD estimators can be subject to bias. However, they appear to converge to the correct value as data become more balanced, while TWFE generally will not.

\section{Monte Carlo Analysis} \label{sec:analysis}
We now perform a Monte Carlo analysis to examine the properties of TWFE models, new DiD estimators, and their performance under various settings such as the proportion of never-treated units in the control group, and the degree of unbalanced data. Our simulations examine how accurately various models can recover the average treatment effect on the treated (ATT) under different treatment effects and data specifications. We test the performance of the standard TWFE model, and the models of \citet{sunabr2021a}, \citet{wooldridge2021two}, \citet{borusyak2024revisiting}, \citet{gardner2022a}, and \citet{CS2021}.
\subsection{Data Description}
We create datasets with 1,000 customers and 20 time periods. In our simulations, certain customers become affected by a price conspiracy, and thus experience an increase in their prices paid. The treatment effect is staggered; customers become treated between times 10 through 15.\footnote{Treatment cohorts are assigned randomly, with each cohort having an equal chance of being assigned. Our data-generating process results in approximately 60\% of units never experiencing the treatment.} Our Monte Carlo analysis analyzes 6 different treatment effect specifications:
\begin{align*}
    \text{Effect 1 (Homogenous, Static)} &= 5\cdot D_{it} \\
    \text{Effect 2 (Heterogeneous, Static)} &= (5 + \text{cohort}_i - \overline{\text{cohort}})\cdot D_{it} \\
    \text{Effect 3 (Homogenous, Dynamic)} &= (5 + \text{exposure}_{it} - \overline{\text{exposure}})\cdot D_{it} \\
    \text{Effect 4 (Heterogeneous, Dynamic)} &= (5 + \text{cohortTime}_{it} - \overline{\text{cohortTime}})\cdot D_{it} \\
    \text{Effect 5 (Homogenous, Dynamic)} &= (5 - \text{exposure}_{it} + \overline{\text{exposure}})\cdot D_{it} \\
    \text{Effect 6 (Heterogeneous, Dynamic)} &= (5 - \text{cohortTime}_{it} + \overline{\text{cohortTime}})\cdot D_{it} \\
    \text{cohortTime} &= \text{cohort}_i + \frac{\text{cohort}_i-10}{5}\cdot \text{exposure}_{it}.
\end{align*}
These treatment effects allow us to identify how heterogeneous and/or dynamic effects factor into the DiD estimators. All effects are normalized so that the true effect we want to recover is equal to 5.

We then add unit and time effects and two standard Normal variables, one for our noise parameter and one as a covariate:
\begin{equation}
     y_{it} = \alpha_i + \lambda_t + x_{it} + \text{Effect}_{it} \cdot D_{it} + \epsilon_{it}.
\end{equation}
Shown below are the true treatment effects by cohort for the 6 different specifications. They capture varying behaviors that would complicate a standard DiD analysis and which the new literature would suggest poses problems for typical estimation methods.
\begin{figure}[H]
    \centering
    \caption{Treatment Effects in Simulated Data}
    \includegraphics[width=5in]{Figures/Table 1 Treatment Effects Chart.jpg}
    \label{fig:treat-effects}
\end{figure}
\subsection{Results}
\subsubsection{Comparing Estimators with Never-Treated Control Group}
In Table \ref{tab:estimators-never}, we compare the finite-sample performance of several estimators under the 6 different scenarios described above. Our Monte Carlo exercise uses 1,000 randomly generated datasets with the 6 different effects, and the reported results are averaged across the simulations.\footnote{Distributions of our Monte Carlo estimators are reported in \hyperref[sec:appendixb]{Appendix B} below. Each regression model is run on each dataset 1,000 times. Each of the 1,000 datasets varies by the pseudo-random variables included in our data-generating process.}

First, we can see that the TWFE results are biased (significantly different from the true ATT) in all but the first dataset; this is consistent with the literature finding that TWFE is biased unless the treatment effect is homogeneous and static. Datasets 5 and 6 confirm that the direction of the staggered DiD bias depends on whether earlier treatment cohorts have higher (or lower) effects than later cohorts.\footnote{For example, in dataset 3, the earliest treatment cohort has the highest treatment effect over time, while the opposite is true for dataset 5. Since earlier-treated cohorts suffer most from negative weights, the high treatment effect is muted by negative weights in dataset 3 (leading to negative bias), and vice versa for dataset 5.}  Note that the magnitude of bias is the same between 3 and 5 (or 4 and 6), but in opposite directions.

Second, we find that all methods from the new literature recover the desired effect, but with varying precision. The Wooldridge, Gardner, and Borusyak et al. methods with the control variable included have the lowest standard errors, which agrees with the literature.\footnote{Prof. Wooldridge establishes equivalence between his method and the Borusyak imputation, and both papers establish BLUE-like properties of their estimators. \citet{borusyak2024revisiting}, p. 16 (Theorem 2). \citet{wooldridge2021two}, p. 6 “Moreover, because the POLS/ETWFE estimator is also equivalent to random effects with known (rather than estimated) transformation parameter, under the standard no serial correlation and homoskedasticity assumptions, the POLS estimator is best linear unbiased. Thus, this simpler estimator has the same efficiency as the comparable imputation estimator in BJS (2021).”}  The Callaway and Sant’Anna method produces significantly larger standard errors, but this approach may still be desirable for its conservative inference and robustness to additional types of misspecification. Further, an interesting result is that the new estimators recover the same estimate \textit{regardless of the treatment effect specification}; their coefficient and standard errors are identical across the table row. Finally, this table quantifies the effects of omitting a time-varying covariate from the regression; omitting this variable increases the standard error of each estimated treatment effect.

Our Monte Carlo analysis also confirms point equivalences between some of the estimators. For instance, the Callaway and Sant’Anna (no covariates) and Sun and Abraham estimators have identical point estimates in each of our 1,000 simulations, when using the never-treated group.\footnote{\citet{sunabr2021a}, p. 187 (“In particular, without covariates and for the case with never treated units, our approach coincides with Callaway and Sant’Anna (2020a).”).}  The Gardner and Borusyak et al. methods have identical point estimates. While the Wooldridge standard errors look identical to Gardner and Borusyak et al., the point estimates are slightly different.
\begin{table}[H]
    \centering
    \caption{Statistical Comparison of DiD Methods with True Average Effect
Comparing Treated with Never-Treated and Not-Yet-Treated}
    \includegraphics[width=6in]{Figures/Table 1.png}
    \label{tab:estimators-never}
\end{table}

\subsubsection{Comparing Estimators with Not-Yet-Treated Control Group}
Next, in Table \ref{tab:estimators-notyet}, we repeat the simulation exercise using only the not-yet-treated group as a control, meaning we remove the never-treated units. However, we cannot simply rerun the models with the remaining data. By time 15, all units are treated, which makes estimation of the treatment effect impossible for times 15 through 20. As a result, we also exclude these time periods from the data.\footnote{Because these filters result in a substantially smaller dataset than the previous table, we increase the number of treated units so that the filtered data is approximately the same size as the original data. We rebalance the true effect to remain at 5.} 

Interestingly, when using the not-yet-treated group only, the TWFE estimates are only weakly different from the true effect under a heterogeneous, static treatment effect. The TWFE point estimates for dataset 2 are different from the other estimators, but substantially closer to the true effect when compared to the previous table. Further, while the Callaway and Sant’Anna (no covariates) and Sun and Abraham estimators were identical in the previous table, the Callaway and Sant’Anna estimator has lower standard errors here. Regardless, all of the new estimators continue to recover the true effect.
\begin{table}[H]
    \centering
    \caption{Statistical Comparison of DiD Methods with True Average Effect
Comparing Treated with Not-Yet-Treated Only}
    \includegraphics[width=6in]{Figures/Table 2.png}
    \label{tab:estimators-notyet}
\end{table}
\subsubsection{TWFE Bias by Composition of Control Group}
Next, we analyze how the composition of the control group affects the resulting TWFE bias. The horizontal axis in Figure \ref{fig:pc-nevertreat} below is the percentage of never-treated units in the control group; 0 means only not-yet-treated observations (no unaffected units), while 100 means only never-treated. The vertical axis is the  estimator bias (estimated effect minus true effect). As expected, when treatment effects are homogeneous and static, there is no bias regardless of never-treated composition. Next, the homogeneous and dynamic specifications (the green and purple lines) have extreme bias when there are only not-yet-treated observations; the bias decreases quickly as we add never-treated units into the control group. The heterogeneous treatment effects (red, yellow, and orange) are much less affected than the homogeneous dynamic effects (green and purple). Interestingly, the bias from our heterogeneous and dynamic specifications (yellow and orange) flip sign at around 35\% never-treated.

We also perform a sensitivity analysis to check if these (and other) findings are robust to alternative data specifications. We randomly vary the number of units, number of time periods, percent never-treated, first treatment time, last treatment time, percent balanced, treatment effect size and sign, individual-specific treatment heterogeneity, covariate effect size and sign, and covariate correlation with treatment status. See \hyperref[sec:appendixb]{Appendix B}, \hyperref[tab:sensitivity-table]{Table 3} and \hyperref[tab:sensitivity-table-interact]{Table 4} for these additional results.
\begin{figure}[H]
    \centering
    \caption{TWFE Bias by Percent Never-Treated in the Data}
    \includegraphics[width=5in]{Figures/TWFE Bias by Percent Never Treated.jpg}
    \label{fig:pc-nevertreat}
\end{figure}
\subsubsection{DiD Estimator Bias for Unbalanced Panels}
To investigate the effects of unbalanced data on DiD estimators, we modify the procedure above to randomly  vary the degree of balance in the data.\footnote{\label{pcunbalancedfn}We create entry and exit by choosing a “cutoff” point uniformly distributed between 0 and 0.5, then generating observation-specific flags for another uniform variable being below the cutoff. The unit’s entry date is the first time that the flag is on, and the exit date is the last time that the flag is on. We then implement filters to prevent instances where the entry and exit dates are the same for a unit. The selected cutoff point varies among datasets.}  Figure \ref{fig:pc-balance} below reports the average bias from each of the 6 treatment effects by \% Balanced, where a value of 100 indicates a balanced panel, and 50 indicates that half of the data is missing (compared to a balanced panel).\footnote{Our method of simulating the data means that unbalanced panels have fewer observations than more balanced ones. We compensate by increasing the balanced size to 50,000 observations (instead of 20,000) and running 10,000 simulations (instead of 1,000). \hyperref[sec:appendixb]{Appendix B} reports scatterplots of each simulated result to demonstrate the increasing spread of bias due to smaller samples.}
\begin{figure}[H]
    \centering
    \caption{TWFE Bias by Percent Balanced Data}
    \includegraphics[width=5in]{Figures/TWFE Bias by Percent Balanced Crop.jpg}
    \label{fig:pc-balance}
\end{figure}
\noindent
Our analysis shows that TWFE bias depends on how unbalanced the panel is when treatment effects are dynamic, even if the exit and entry is not a function of treatment status. Bias is substantially lessened for balanced panels when treatment effects are homogeneous and dynamic, but it increases slightly when treatment effects are heterogenous and dynamic.

Now, we compare the TWFE bias for unbalanced panels to the new estimators. First, we observe biased estimators for highly unbalanced panels in all estimators except the Sun and Abraham model. This is particularly interesting given our reported equivalence between that estimator and the Callaway and Sant’Anna model in a balanced setting. Bias only occurs for the new estimators when the treatment effect is dynamic (effects 3 through 6), though bias is very small when those dynamic effects are heterogeneous (effects 4 and 6). We see that all the new estimators converge to the correct effect as the data becomes more balanced, while that is not true for the TWFE estimators. Finally, note that the direction of the bias is the same for a given treatment effect specification: when treatment effects increase over time (effect 3), bias is negative, and vice versa when treatment effects decrease over time (effect 5).\footnote{While exit and entry in our simulated data is not a function of treatment status, it is correlated indirectly. To investigate, we combined 100 randomly generated datasets using the same method as in our analysis, and stacked the data. Examining the distribution of the data over time, we see that the earliest and latest periods of treatment status are most likely to be removed from the data, explaining the direction of bias. See Figure \ref{fig:dist-treat} in \hyperref[sec:appendixb]{Appendix B}.}
\begin{figure}[H]
    \centering
    \caption{Statistical Comparison of DiD Methods with True Average Effect by Percent Balanced}
    \includegraphics[width=6in]{Figures/Binscatters by Percent Balanced Common Scale.jpg}
    \label{fig:estimators-balanced}
\end{figure}
\section{Conclusion} \label{sec:conclusion}
\singlespace
Difference-in-differences analysis is one of the most important techniques for policy evaluation in the social sciences, and will continue to be used frequently in antitrust work. The recent literature has shown that traditional DiD techniques are subject to mismeasurement under a variety of realistic situations. But this literature has also provided a suite of new tools that can examine policy effects with more detail and clarity than ever before. We reviewed the new estimators and discussed their strengths and weaknesses as it pertains to common antitrust analysis. Our Monte Carlo analysis confirms findings from the literature, and it exposes unbalanced data as a source of bias that even the new estimators can mismeasure. Our discussions and list of recommended sensitivities will hopefully provide antitrust practitioners and other applied economists with the rigor needed for DiD work going forward.

\newpage
\doublespace
\printbibliography
\addcontentsline{toc}{section}{References}

\newpage
\section*{Appendix A. Recommended Sensitivities} \label{sec:appendixa}
\addcontentsline{toc}{section}{Appendix A. Recommended Sensitivities}
Here we provide a list of recommended sensitivities when performing staggered DiD analysis. Practitioners can use this as a reference checklist to ensure the robustness of their results. Substantial deviations in any sensitivities may call for a closer look at your model and assumptions. Similarly, this checklist could be used by experts responding to a DiD analysis as a method for evaluating its robustness. Conclusions will always depend on circumstances of the case, including data availability. Passing or failing any of these tests does not necessarily validate or invalidate a result. Finally, this list does not address general model specification sensitivities, only the robustness of the staggered DiD framework; additional checks on functional form, appropriate controls, and others still apply.
\begin{enumerate}
    \item Sensitivities on appropriate control group:
    \begin{enumerate}
        \item Use never-treated only as the control group
        \item Use not-yet-treated only as the control group
        \item Use both never-treated and not-yet-treated
        \item Perform tests to assess whether the not-yet-treated and never-treated groups are systematically different. For example, you might run placebo tests where the not-yet-treated group is a pseudo-treatment group, and never-treated is the pseudo-control. This can also reveal anticipation effects if the not-yet-treated units have different behavior than the never-treated.
    \end{enumerate}
    \item Sensitivities on heterogeneous treatment effects:
    \begin{enumerate}
        \item Estimate cohort-time interacted effects and perform Wald tests among DiD coefficients. Accomplish this with some form of the Wooldridge ETWFE estimator (or Sun/Abraham with no coefficients), depending on computation limits and context-specific knowledge of treatment effect heterogeneity. If the Wald tests show treatment effects are not equal between cohorts, consider incorporating cohort-specific treatment effects in the model.
        \item Aggregate the cohort-time specific treatment effects by observed probabilities  as well as other relevant metrics like revenue or volume.\footnote{\citet{sunabr2021a}, p. 186 (Section 4.1).}  Compare these results to the single-coefficient TWFE or standard DiD model.
        \begin{enumerate}
            \item Importantly, assess the economic significance of any difference between a TWFE model and the new estimators. In our experience, in big datasets, the statistical significance of such a difference may not solely determine whether a TWFE model is inappropriate.
        \end{enumerate}
        \item Run an imputation-style estimator (Gardner or Borusyak et al.), especially if you prefer to estimate a single DiD coefficient.\footnote{\citet{gardner2022a}, Section 3. \citet{borusyak2024revisiting}, p. 16 (Theorem 2).}  These estimators can be very quick (and thus attractive for large data), but they have limitations with unbalanced panels as described above. If including covariates in the model, be mindful of the implicit assumption that covariates do not affect treatment status and vice versa.\footnote{See \citet{gardner2022a}, note 9. Be prepared to support this assumption with additional analysis.}  These models make explicit but-for predictions for the treatment group that can be aggregated many different ways. This can be useful for assessing systematic differences present in the data.
        \item Run a Sun and Abraham-style auxiliary regression (Their equation 13 following Proposition 1) to estimate TWFE treatment weights. You can also use the method from \citet{borusyak2024revisiting} Proof of Proposition 2. Assess relationships between these weights and observables such as time. This is especially useful when binning the data, as demonstrated in \citet{borusyak2024revisiting} Section 5.2.1.
         \begin{enumerate}
            \item If using a TWFE-style model, examine the weights over many subsets of the data. For example, see if certain subsets get systematically negative weight, and understand how that might bias your results. For examples of visualizations of negative weights, see \citet{jakiela2021a}, Figures 2 through 4.
        \end{enumerate}
        \item Consider whether the treatment effect may vary by other observables, and measure their effects separately if needed. For example, are certain products likely to see higher price increases from a conspiracy? Or, in a class action context, it could be that some groups of customers were not affected by the alleged conduct. While measuring many separate treatment effects can be useful, doing so to intentionally lower the precision of someone’s model is bad practice. Further, using iterated regressions to find a subset of units with no treatment effect is subject to model selection bias.
    \end{enumerate}
    \item Sensitivities on parallel trends:
    \begin{enumerate}
        \item \label{butfor-item} Use your preferred model to predict the but-for outcome for treated observations. Then compare but-for outcomes to observed outcomes before the treatment starts, for example by plotting these lines for each treated unit. This method tests whether your control group provides a good approximation to your treatment group before the treatment starts.
        \item Run a Sun and Abraham- or Wooldridge-style cohort-interacted event study with the full set of relative-time indicators (including negative exposure times), then assess the pre-treatment coefficients.
        \item Run a \citet{borusyak2024revisiting}-style placebo test on untreated observations.\footnote{\citet{borusyak2024revisiting}, p. 21 (Test 1). Note their discussion of alternative placebo tests and their associated drawbacks in pp. 21-22.
        \\\\
        Keep in mind the visual interpretation guidelines from \citet{roth2024a} for new estimators. In particular, the Borusyak et al. imputation estimator pre-trend coefficients should be considered separately from post-trend coefficients. \citet{roth2024a}, Section 3.3.}
        \item Assess maximal parallel trend violations and use it to size the possible impact to your treatment effect.\footnote{\citet{rambachan2023more}, Section 6.2, and Figures 5 and 7 in particular.}
        \item Assess whether postestimation parallel trends tests are likely to be underpowered in the available data.
        \item Estimate a model with product-specific time trends in the style of \citet{wooldridge2021two}, Equation 7.14 (which substitutes time fixed effects for unit-specific time trends).\footnote{Stata’s popular third-party package \texttt{reghdfe} allows for faster estimation of these types of models if you do not care about the coefficients of the unit-specific time trends (also called fixed slopes estimation). See also \citet{ruttenauer2023fixed} and their package \texttt{xtfeis}.}  This relaxes the parallel trends assumption to allow treated units to have different linear trends than the control units.\footnote{\citet{ruttenauer2023fixed} is an excellent resource for panel models with unit-specific trends. They discuss the benefits and drawbacks of adding these time trends to your model. They specify Hausman-style tests of unit-specific trends vs fixed or random effects models (interpretable as a parallel trends test). Finally, they provide a wealth of citations both for and against this type of model.}  This can also be used as evidence in favor of (or against) common trends. With enough data, you could add polynomial terms to the model to allow for more flexible differences in pre-trends.\footnote{For example, your regression could have product fixed effects, then product fixed effects interacted with (continuous) time, product fixed effects interacted with time squared, and so on. These models do not include separate time fixed effects. Keep in mind that this specification will exclude products with few observations, which can be especially problematic with unbalanced panels. \citet{ruttenauer2023fixed}, p. 74.}  Visually compare the fit from this model to the method described in sensitivity \ref{butfor-item}.
    \end{enumerate}
    \item Sensitivities on selection bias:
    \begin{enumerate}
        \item Test for correlation between treatment status and observables with an auxiliary regression using treatment status as your outcome variable.
        \item Perform typical panel attrition tests.\footnote{\citet{wooldridge2010a}, Chapter 17.7.3.}  Include an indicator for “drops out of data in next period” in your model and assess its coefficient. Are certain groups in the data more likely to exit than others?
        \item To the extent that exit bias may exist, try to evaluate the expected direction of the bias. For example, if customers drop out because their price becomes too high, and you are modelling prices, consider whether your treatment effect is underestimated.
    \end{enumerate}
    \item Sensitivities for entry and exit in both control and treatment groups:
    \begin{enumerate}
        \item Estimate your model by removing all agents that are partially in the data before and after the policy date.
        \item Remove agents that are only in the before period\footnote{Depending on the policy of interest, it can be possible to identify a product or customer that drops out of the data \textit{before} they start their treatment. For example, you may have outside information that identifies treatment status.} or only in the after period (always-treated). Test whether they significantly change the estimate of the policy effect.
        \item If there are treatment agents that enter into the data after the policy is implemented (always-treated), perform analysis to determine if the new treatment entrants are different from the other treated agents. If they are different, try to adjust the model such that you can estimate their policy effect separately.
        \item If going forward with a TWFE model, use the estimated weight techniques from above to assess the always-treated group in detail. Beware that it can be highly subject to negative weighting issues.
        \item Compare a Sun and Abraham-style estimator to any other new estimators used, especially when the data is highly unbalanced. A large difference between the two may indicate bias stemming from treatment status correlation with entry and exit.
    \end{enumerate}
\end{enumerate}
\newpage
\section*{Appendix B. Additional Monte Carlo Results} \label{sec:appendixb}
\addcontentsline{toc}{section}{Appendix B. Additional Monte Carlo Results}

\begin{figure}[H]
    \centering
    \caption{Distributions of Monte Carlo Estimates in Table \ref{tab:estimators-never}}
    \includegraphics[width=6in]{Figures/Histograms of Monte Carlo Estimates 1.jpg}
    \label{fig:hist1}
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Distributions of Monte Carlo Estimates in Table \ref{tab:estimators-notyet}}
    \includegraphics[width=6in]{Figures/Histograms of Monte Carlo Estimates 2.jpg}
    \label{fig:hist2}
\end{figure}

\begin{figure}
    \centering
    \caption{TWFE Bias by Percent Never-Treated in the Data (Scatter Plot)}
    \includegraphics[width=5in]{Figures/TWFE Bias by Percent Never Treated Scatter.jpg}
    \label{fig:scatter-nevertreat}
\end{figure}

\begin{figure}
    \centering
    \caption{TWFE Bias by Percent Balanced (Scatter Plot)}
    \includegraphics[width=5in]{Figures/TWFE Bias by Percent Balanced Scatter Crop.jpg}
    \label{fig:scatter-balance}
\end{figure}

\begin{figure}
    \centering
    \caption{Statistical Comparison of DiD Methods with True Average Effect by Percent Balanced (Relative Scale)}
    \includegraphics[width=6in]{Figures/Binscatters by Percent Balanced Relative Scale.jpg}
    \label{fig:bins-relative}
\end{figure}

\begin{figure}
    \centering
    \caption{Statistical Comparison of DiD Methods with True Average Effect by Percent Balanced (Scatter Plot)}
    \includegraphics[width=6in]{Figures/Scatters by Percent Balanced Common Scale.jpg}
    \label{fig:scatters-common}
\end{figure}

\begin{figure}
    \centering
    \caption{Statistical Comparison of DiD Methods with True Average Effect by Percent Balanced (Scatter Plot) (Relative Scale)}
    \includegraphics[width=6in]{Figures/Scatters by Percent Balanced Relative Scale.jpg}
    \label{fig:scatters-relative}
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Average Distribution of Data in Unbalanced Simulations by Treatment Status (Data Underlying Figure \ref{fig:pc-balance})}
    \includegraphics[width=5in]{Figures/Average Distribution of Data in Unbalanced Simulations by Treated.jpg}
    \label{fig:dist-treat}
\end{figure}

To construct our sensitivity tables shown below, we randomly generated 50,000 regression datasets and ran 6 TWFE models (for the 6 different treatment effects) on each one. The parameters we varied in the data are as follows:
\begin{center}
\begin{tabular}{r|l}
    Time periods ($T$) & $\{5, 10, \ldots, 50\}$ \\
    Units & $\{500, 1000, \ldots, 5000\}$\\
    First cohort time ($T_{\text{start}}$) & $\{(T/5)+3, \ldots, T-1 \}$\\
    Last cohort time & $\{T_{\text{start}}+1, \ldots, T\}$\\
    \% Never Treated & \text{Uniform}(0, 1) \\
    \% Balanced & \hyperref[pcunbalancedfn]{\textbf{Described above}} \\
    True effect size & $\{-10, -9, \ldots, 10\}$\\
    Covariate size & \text{Uniform}(-5, 5) \\
\end{tabular}
\end{center}
There are two additional data modifiers. For 25\% of the datasets, we add an individual-specific treatment effect modifier. This randomly adjusts the true treatment effect at the observation level by a mean-zero Normal distribution, where the standard deviation is randomly chosen as a function of the true effect size. Essentially, it adds noise to the true treatment effect at the observation level. Also, for 25\% of the datasets, we adjust our covariate by randomly picking a number from a standard Normal distribution, and adding that number to our covariate when $D_{it}=1$, inducing correlation between the covariate and treatment status. Some additional records are dropped due to a combination of variables resulting in an inestimable dataset.

\newgeometry{left=0.5in,bottom=0.5in,right=0.5in,top=0.5in,includefoot}

\begin{landscape}
\begin{table}[htbp]\centering
\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
\caption{Regressions of Absolute TWFE Bias}
\label{tab:sensitivity-table}
\scalebox{0.7}{
\begin{tabular}{l*{6}{c}}
\hline\hline
                                        &\multicolumn{1}{c}{(1)}&\multicolumn{1}{c}{(2)}&\multicolumn{1}{c}{(3)}&\multicolumn{1}{c}{(4)}&\multicolumn{1}{c}{(5)}&\multicolumn{1}{c}{(6)}\\
                    &\multicolumn{1}{c}{Data 1}&\multicolumn{1}{c}{Data 2}&\multicolumn{1}{c}{Data 3}&\multicolumn{1}{c}{Data 4}&\multicolumn{1}{c}{Data 5}&\multicolumn{1}{c}{Data 6}\\
                    &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         \\
\hline
\% Never-Treated    &      -0.005\sym{***}&      -0.006\sym{***}&      -0.049\sym{***}&      -0.103\sym{***}&      -0.050\sym{***}&      -0.103\sym{***}\\
                    &     (0.000)         &     (0.001)         &     (0.001)         &     (0.001)         &     (0.001)         &     (0.001)         \\
\% Never-Treated Squared&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.001\sym{***}&       0.000\sym{***}&       0.001\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
Count of Units (1000s)&      -0.084\sym{***}&      -0.077\sym{***}&      -0.051\sym{***}&      -0.053\sym{***}&      -0.051\sym{***}&      -0.057\sym{***}\\
                    &     (0.005)         &     (0.005)         &     (0.007)         &     (0.015)         &     (0.007)         &     (0.015)         \\
First Treatment Time&       0.000         &      -0.006\sym{***}&      -0.010\sym{***}&       0.108\sym{***}&      -0.010\sym{***}&       0.108\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.001)         &     (0.000)         &     (0.001)         \\
Longest Treatment Exposure Time&      -0.004\sym{***}&       0.031\sym{***}&       0.123\sym{***}&       0.173\sym{***}&       0.123\sym{***}&       0.172\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.001)         &     (0.001)         &     (0.001)         &     (0.001)         \\
\% Balanced         &      -0.032\sym{***}&      -0.033\sym{***}&      -0.048\sym{***}&      -0.089\sym{***}&      -0.048\sym{***}&      -0.089\sym{***}\\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.002)         &     (0.001)         &     (0.002)         \\
\% Balanced Squared &       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.001\sym{***}&       0.000\sym{***}&       0.001\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
True Effect Size    &       0.001         &       0.001\sym{*}  &       0.000         &      -0.001         &       0.000         &      -0.000         \\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.002)         &     (0.001)         &     (0.002)         \\
Individual-Specific Treatment Noise&       0.025\sym{***}&       0.026\sym{***}&       0.016\sym{**} &       0.023         &       0.016\sym{**} &       0.018         \\
                    &     (0.004)         &     (0.005)         &     (0.006)         &     (0.013)         &     (0.006)         &     (0.013)         \\
Covariate Treatment Correlation&       0.001         &       0.148\sym{***}&      -0.533\sym{***}&      -0.297\sym{***}&       0.545\sym{***}&       0.322\sym{***}\\
                    &     (0.007)         &     (0.007)         &     (0.009)         &     (0.021)         &     (0.009)         &     (0.021)         \\
Covariate Size      &       0.000         &       0.000         &       0.000         &       0.002         &       0.001         &       0.003         \\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.003)         &     (0.001)         &     (0.003)         \\
Constant            &       1.133\sym{***}&       1.129\sym{***}&       2.914\sym{***}&       3.694\sym{***}&       2.915\sym{***}&       3.709\sym{***}\\
                    &     (0.016)         &     (0.018)         &     (0.023)         &     (0.051)         &     (0.023)         &     (0.050)         \\
\hline
Row Count           &   49116         &   49116         &   49116         &   49116         &   49116         &   49116         \\
Adjusted $R^2$  &       0.115         &       0.171         &       0.577         &       0.462         &       0.578         &       0.464         \\
$F$ Statistic         &     580.558         &     922.596         &    6079.892         &    3833.185         &    6124.682         &    3871.689         \\
$\chi^2$ p-value &       0.000         &       0.000         &       0.000         &       0.000         &       0.000         &       0.000         \\
\hline\hline
\multicolumn{7}{l}{\footnotesize \sym{*} \(p<0.05\), \sym{**} \(p<0.01\), \sym{***} \(p<0.001\)}\\
\end{tabular}
}
\footnotesize  
\vspace{5mm}
    \footnotesize \begin{singlespace*}
        Each observation in this regression is the result of a TWFE model run on data which randomly changes each of the parameters shown here.
    \end{singlespace*}
\end{table}
\end{landscape}

\begin{table}[htbp]\centering
\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
\caption{Regressions of Absolute TWFE Bias (Interacted)}
\label{tab:sensitivity-table-interact}
\scalebox{0.5}{
\begin{tabular}{p{4.5in}|*{6}{c}}
\hline\hline
                    &\multicolumn{1}{c}{(1)}&\multicolumn{1}{c}{(2)}&\multicolumn{1}{c}{(3)}&\multicolumn{1}{c}{(4)}&\multicolumn{1}{c}{(5)}&\multicolumn{1}{c}{(6)}\\
                    &\multicolumn{1}{c}{Data 1}&\multicolumn{1}{c}{Data 2}&\multicolumn{1}{c}{Data 3}&\multicolumn{1}{c}{Data 4}&\multicolumn{1}{c}{Data 5}&\multicolumn{1}{c}{Data 6}\\
                    &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         &Coefficient/SE         \\
\hline
\% Never-Treated    &      -0.020\sym{***}&      -0.018\sym{***}&      -0.015\sym{***}&       0.050\sym{***}&      -0.017\sym{***}&       0.056\sym{***}\\
                    &     (0.002)         &     (0.002)         &     (0.002)         &     (0.005)         &     (0.002)         &     (0.005)         \\
\% Never-Treated Squared&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&      -0.000\sym{**} &       0.000\sym{***}&      -0.000\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
Count of Units (1000s)&      -0.078\sym{***}&      -0.066\sym{***}&      -0.011         &      -0.045         &      -0.021         &      -0.021         \\
                    &     (0.014)         &     (0.016)         &     (0.017)         &     (0.038)         &     (0.016)         &     (0.037)         \\
First Treatment Time&      -0.000         &      -0.004\sym{***}&      -0.029\sym{***}&       0.247\sym{***}&      -0.030\sym{***}&       0.248\sym{***}\\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.003)         &     (0.001)         &     (0.003)         \\
Longest Treatment Exposure Time&      -0.004\sym{***}&       0.025\sym{***}&       0.273\sym{***}&       0.421\sym{***}&       0.273\sym{***}&       0.422\sym{***}\\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.003)         &     (0.001)         &     (0.003)         \\
\% Balanced         &      -0.027\sym{***}&      -0.027\sym{***}&      -0.039\sym{***}&      -0.111\sym{***}&      -0.038\sym{***}&      -0.109\sym{***}\\
                    &     (0.002)         &     (0.002)         &     (0.002)         &     (0.004)         &     (0.002)         &     (0.004)         \\
\% Balanced Squared &       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.001\sym{***}&       0.000\sym{***}&       0.001\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
True Effect Size    &       0.002         &       0.003         &       0.000         &      -0.006         &      -0.001         &      -0.006         \\
                    &     (0.002)         &     (0.002)         &     (0.002)         &     (0.005)         &     (0.002)         &     (0.005)         \\
Individual-Specific Treatment Noise&       0.051\sym{***}&       0.051\sym{***}&       0.031\sym{*}  &       0.091\sym{**} &       0.030\sym{*}  &       0.072\sym{*}  \\
                    &     (0.012)         &     (0.014)         &     (0.014)         &     (0.033)         &     (0.014)         &     (0.032)         \\
True Effect Size $\times$ Individual-Specific Treatment Noise&       0.003\sym{*}  &       0.004\sym{*}  &       0.001         &       0.003         &       0.003         &       0.003         \\
                    &     (0.002)         &     (0.002)         &     (0.002)         &     (0.004)         &     (0.002)         &     (0.004)         \\
Covariate Treatment Correlation&       0.063\sym{**} &       0.126\sym{***}&      -0.786\sym{***}&      -0.528\sym{***}&       0.804\sym{***}&       0.463\sym{***}\\
                    &     (0.020)         &     (0.022)         &     (0.024)         &     (0.054)         &     (0.023)         &     (0.053)         \\
Covariate Size      &      -0.001         &       0.002         &       0.005         &      -0.027\sym{**} &       0.001         &      -0.020\sym{*}  \\
                    &     (0.003)         &     (0.003)         &     (0.004)         &     (0.008)         &     (0.004)         &     (0.008)         \\
Covariate Treatment Correlation $\times$ Covariate Size&      -0.003         &      -0.000         &       0.008         &      -0.004         &       0.008         &      -0.001         \\
                    &     (0.006)         &     (0.007)         &     (0.007)         &     (0.017)         &     (0.007)         &     (0.017)         \\
\% Never-Treated $\times$ Count of Units (1000s)&       0.002\sym{*}  &       0.001         &       0.001         &       0.002         &       0.001         &       0.001         \\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.002)         &     (0.001)         &     (0.002)         \\
\% Never-Treated $\times$ First Treatment Time&       0.000         &      -0.000         &       0.001\sym{***}&      -0.004\sym{***}&       0.001\sym{***}&      -0.004\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated $\times$ Longest Treatment Exposure Time&       0.000\sym{*}  &       0.000\sym{***}&      -0.005\sym{***}&      -0.008\sym{***}&      -0.005\sym{***}&      -0.008\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated $\times$ \% Balanced&       0.000\sym{***}&       0.000\sym{***}&       0.000         &       0.001\sym{***}&       0.000\sym{*}  &       0.001\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated $\times$ \% Balanced Squared&      -0.000\sym{***}&      -0.000\sym{***}&      -0.000\sym{**} &      -0.000\sym{***}&      -0.000\sym{**} &      -0.000\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated $\times$ True Effect Size&      -0.000         &      -0.000         &      -0.000         &       0.000         &      -0.000         &       0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated $\times$ Individual-Specific Treatment Noise&      -0.002\sym{***}&      -0.002\sym{***}&      -0.002\sym{*}  &      -0.004\sym{**} &      -0.002\sym{**} &      -0.004\sym{**} \\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.002)         &     (0.001)         &     (0.002)         \\
\% Never-Treated $\times$ True Effect Size $\times$ Individual-Specific Treatment Noise&      -0.000\sym{*}  &      -0.000\sym{*}  &      -0.000         &      -0.000         &      -0.000         &      -0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated $\times$ Covariate Treatment Correlation&      -0.003\sym{**} &       0.000         &       0.004\sym{***}&       0.003         &      -0.006\sym{***}&      -0.001         \\
                    &     (0.001)         &     (0.001)         &     (0.001)         &     (0.002)         &     (0.001)         &     (0.002)         \\
\% Never-Treated $\times$ Covariate Size&       0.000         &      -0.000         &      -0.000         &       0.001\sym{***}&      -0.000         &       0.001\sym{**} \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated $\times$ Covariate Treatment Correlation $\times$ Covariate Size&       0.001         &       0.001         &       0.000         &       0.000         &       0.000         &      -0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.001)         &     (0.000)         &     (0.001)         \\
\% Never-Treated Squared $\times$ Count of Units (1000s)&      -0.000\sym{***}&      -0.000\sym{**} &      -0.000\sym{**} &      -0.000\sym{*}  &      -0.000\sym{**} &      -0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ First Treatment Time&      -0.000         &       0.000         &      -0.000\sym{***}&       0.000\sym{***}&      -0.000\sym{***}&       0.000\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ Longest Treatment Exposure Time&      -0.000\sym{**} &      -0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ \% Balanced&      -0.000\sym{***}&      -0.000\sym{***}&      -0.000\sym{***}&      -0.000\sym{***}&      -0.000\sym{***}&      -0.000\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ \% Balanced Squared&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}\\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ True Effect Size&       0.000         &       0.000         &       0.000         &      -0.000         &       0.000         &      -0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ Individual-Specific Treatment Noise&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{**} &       0.000\sym{***}&       0.000\sym{**} \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ True Effect Size $\times$ Individual-Specific Treatment Noise&       0.000\sym{*}  &       0.000\sym{*}  &       0.000         &       0.000         &       0.000         &       0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ Covariate Treatment Correlation&       0.000\sym{**} &       0.000         &       0.000         &       0.000         &       0.000         &      -0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ Covariate Size&      -0.000         &       0.000         &       0.000         &      -0.000\sym{**} &       0.000         &      -0.000\sym{*}  \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
\% Never-Treated Squared $\times$ Covariate Treatment Correlation $\times$ Covariate Size&      -0.000\sym{*}  &      -0.000\sym{*}  &      -0.000         &      -0.000         &      -0.000         &      -0.000         \\
                    &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         &     (0.000)         \\
Constant            &       1.058\sym{***}&       1.013\sym{***}&       1.454\sym{***}&      -1.245\sym{***}&       1.471\sym{***}&      -1.313\sym{***}\\
                    &     (0.039)         &     (0.043)         &     (0.046)         &     (0.104)         &     (0.045)         &     (0.104)         \\
\hline
Row Count           &   49116         &   49116         &   49116         &   49116         &   49116         &   49116         \\
Adjusted $R^2$  &       0.136         &       0.188         &       0.712         &       0.610         &       0.716         &       0.613         \\
$F$ Statistic         &     221.297         &     326.617         &    3467.513         &    2196.604         &    3540.370         &    2223.260         \\
$\chi^2$ p-value &       0.000         &       0.000         &       0.000         &       0.000         &       0.000         &       0.000         \\
\hline\hline
\multicolumn{7}{l}{\footnotesize \sym{*} \(p<0.05\), \sym{**} \(p<0.01\), \sym{***} \(p<0.001\)}\\
\end{tabular}
}
\footnotesize  
\vspace{5mm}
    \footnotesize \begin{singlespace*}
        Each observation in this regression is the result of a TWFE model run on data which randomly changes each of the parameters shown here.
    \end{singlespace*}
\end{table}

\end{document}